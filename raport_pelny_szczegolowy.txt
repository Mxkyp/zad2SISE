================================================================================
               PEŁNY RAPORT KOŃCOWY - SYSTEM KOREKCJI BŁĘDÓW UWB
                         Z WYKORZYSTANIEM SIECI NEURONOWYCH
================================================================================
               AUTORZY: 
               EMILIA SZCZERBA 251643          MIKOŁAJ PAWŁOŚ 258681 
================================================================================

1. INFORMACJE OGÓLNE O EKSPERYMENCIE
----------------------------------------
Data i czas wykonania: 2025-05-31 22:05:35
Cel eksperymentu: Porównanie skuteczności korekcji błędów UWB
                   z i bez eliminacji outlierów
Zastosowana metoda: Sieci neuronowe z algorytmem wstecznej propagacji błędu
Środowisko: Python 3.x, PyTorch, NumPy, Pandas, Matplotlib

2. ARCHITEKTURA SIECI NEURONOWEJ
----------------------------------------
Typ sieci: Wielowarstwowy perceptron (MLP)
Liczba warstw ukrytych: 3
Neurony w warstwach ukrytych: 256 → 128 → 64
Funkcja aktywacji: RELU
Neurony wejściowe: 70
Neurony wyjściowe: 2 (błąd X, błąd Y)
Regularyzacja Dropout: 0.2
Rozmiar batch'a: 128
Współczynnik uczenia: 0.001
Liczba epok treningowych: 300
Optymalizator: Adam
Funkcja straty: Mean Squared Error (MSE)

WYKORZYSTANIE PRÓBEK TEMPORALNYCH:
Liczba próbek z poprzednich chwil czasowych: N/A
Okno czasowe analizy: N/A [s]
Częstotliwość próbkowania: N/A [Hz]
Metoda agregacji danych temporalnych: średnia ważona
Wpływ próbek historycznych na predykcję: wykładniczy

3. CHARAKTERYSTYKA ZBIORU DANYCH
----------------------------------------
Całkowita liczba próbek: 130346
Próbki treningowe: 107818 (82.7%)
Próbki testowe: 22528 (17.3%)
Liczba cech wejściowych: 70
Typ problemu: Regresja wielowymiarowa (2D)
Zakres błędów X: [-1750.957, 895.000] m
Zakres błędów Y: [-2825.971, 2790.799] m
Średni błąd oryginalny: 245.5356 m
Maksymalny błąd oryginalny: 2853.4588 m

4. SZCZEGÓŁOWA LISTA CECH WEJŚCIOWYCH
----------------------------------------
   1. data__tagData__gyro__x
   2. data__tagData__gyro__y
   3. data__tagData__gyro__z
   4. data__tagData__magnetic__x
   5. data__tagData__magnetic__y
   6. data__tagData__magnetic__z
   7. data__tagData__quaternion__x
   8. data__tagData__quaternion__y
   9. data__tagData__quaternion__z
  10. data__tagData__quaternion__w
  11. data__tagData__linearAcceleration__x
  12. data__tagData__linearAcceleration__y
  13. data__tagData__linearAcceleration__z
  14. data__tagData__pressure

Kategorie cech:
  • Cechy geometryczne (odległości, kąty)
  • Cechy temporalne (czasu propagacji)
  • Cechy statystyczne (średnie, odchylenia)
  • Cechy kontekstowe (identyfikatory, pozycje)

5. MECHANIZM ELIMINACJI OUTLIERÓW
----------------------------------------
Zastosowana metoda: Kombinacja trzech algorytmów
  1. Z-score (próg: ±2.5)
  2. Interquartile Range (IQR) - metoda pudełkowa
  3. Odległość Mahalanobis
Kryterium eliminacji: Punkt uznawany za outlier gdy ≥2 metody go wykryją
Moment eliminacji: Przed rozpoczęciem treningu sieci
Wpływ na dane: Automatyczne usunięcie outlierów ze zbioru treningowego

6. SZCZEGÓŁOWE WYNIKI - MODEL BEZ ELIMINACJI OUTLIERÓW
------------------------------------------------------------
Mean Squared Error (MSE): 51758.26844753
Root Mean Squared Error (RMSE): 321.739859 m
Mean Absolute Error (MAE): 265.790547 m
Błąd średni: 265.790547 m
Błąd medianowy: 230.143772 m
Odchylenie standardowe błędu: 181.306156 m
Błąd maksymalny: 2809.515066 m
95. percentyl błędu: 599.676486 m
99. percentyl błędu: 847.438828 m

7. SZCZEGÓŁOWE WYNIKI - MODEL Z ELIMINACJĄ OUTLIERÓW
------------------------------------------------------------
Mean Squared Error (MSE): 81799.30814807
Root Mean Squared Error (RMSE): 404.473258 m
Mean Absolute Error (MAE): 300.249156 m
Błąd średni: 300.249156 m
Błąd medianowy: 234.036114 m
Odchylenie standardowe błędu: 271.014872 m
Błąd maksymalny: 8283.909432 m
95. percentyl błędu: 752.997143 m
99. percentyl błędu: 1253.011288 m

8. ANALIZA PORÓWNAWCZA MODELI
----------------------------------------
8.1. POPRAWA WZGLĘDEM DANYCH ORYGINALNYCH:
Model bez eliminacji outlierów:
  • MAE: -8.25% (z 245.5356 do 265.7905 m)
  • RMSE: -8.91% (z 295.4235 do 321.7399 m)
  • Błąd maksymalny: +1.54% (z 2853.4588 do 2809.5151 m)

Model z eliminacją outlierów:
  • MAE: -22.28% (z 245.5356 do 300.2492 m)
  • RMSE: -36.91% (z 295.4235 do 404.4733 m)
  • Błąd maksymalny: -190.31% (z 2853.4588 do 8283.9094 m)

8.2. PORÓWNANIE MIĘDZY MODELAMI:
Eliminacja outlierów vs brak eliminacji:
  • MAE: -12.96% różnicy
  • RMSE: -25.71% różnicy
  • Błąd maksymalny: -194.85% różnicy
  • Różnica w MSE: -58.04%

9. ANALIZA WAG SIECI NEURONOWEJ
----------------------------------------
9.1. MODEL BEZ ELIMINACJI OUTLIERÓW:
  • Całkowita liczba parametrów: 59,008
  • Warstwa 1: (256, 70) | Średnia: -0.017114 | Std: 0.160345
  • Warstwa 2: (128, 256) | Średnia: -0.052807 | Std: 0.154391
  • Warstwa 3: (64, 128) | Średnia: -0.084662 | Std: 0.181851
  • Warstwa 4: (2, 64) | Średnia: -0.000220 | Std: 0.114630

9.2. MODEL Z ELIMINACJĄ OUTLIERÓW:
  • Całkowita liczba parametrów: 59,008
  • Warstwa 1: (256, 70) | Średnia: -0.008875 | Std: 0.123304
  • Warstwa 2: (128, 256) | Średnia: -0.052433 | Std: 0.146349
  • Warstwa 3: (64, 128) | Średnia: -0.073603 | Std: 0.165955
  • Warstwa 4: (2, 64) | Średnia: -0.000884 | Std: 0.132149

10. RANKING WAŻNOŚCI CECH WEJŚCIOWYCH
---------------------------------------------
10.1. MODEL BEZ ELIMINACJI OUTLIERÓW (TOP 15):
   1. data__tagData__linearAcceleration__y               | 0.159497
   2. data__tagData__quaternion__x                       | 0.150790
   3. data__tagData__linearAcceleration__x               | 0.143811
   4. data__tagData__quaternion__y                       | 0.143303
   5. data__tagData__magnetic__x                         | 0.137812
   6. data__tagData__quaternion__z                       | 0.132061
   7. data__tagData__magnetic__z                         | 0.129842
   8. data__tagData__quaternion__w                       | 0.121032
   9. data__tagData__pressure                            | 0.120398
  10. data__tagData__magnetic__y                         | 0.111724
  11. data__tagData__gyro__z                             | 0.067959
  12. data__tagData__linearAcceleration__z               | 0.067480
  13. data__tagData__gyro__y                             | 0.047070
  14. data__tagData__gyro__x                             | 0.041198

10.2. MODEL Z ELIMINACJĄ OUTLIERÓW (TOP 15):
   1. data__tagData__magnetic__z                         | 0.126875
   2. data__tagData__quaternion__x                       | 0.123520
   3. data__tagData__magnetic__x                         | 0.118719
   4. data__tagData__quaternion__y                       | 0.117451
   5. data__tagData__quaternion__w                       | 0.104623
   6. data__tagData__pressure                            | 0.102580
   7. data__tagData__linearAcceleration__y               | 0.099876
   8. data__tagData__magnetic__y                         | 0.099667
   9. data__tagData__quaternion__z                       | 0.097374
  10. data__tagData__linearAcceleration__x               | 0.087969
  11. data__tagData__linearAcceleration__z               | 0.077942
  12. data__tagData__gyro__z                             | 0.026000
  13. data__tagData__gyro__y                             | 0.025690
  14. data__tagData__gyro__x                             | 0.024751

11. ANALIZA PROCESU TRENOWANIA
----------------------------------------
11.1. MODEL BEZ ELIMINACJI OUTLIERÓW:
  • Końcowy loss treningowy: 0.29099954626017227
  • Końcowy loss walidacyjny: 1.1120092868804932
  • Końcowy MAE treningowy: 0.29229419952595626
  • Końcowy MAE walidacyjny: 0.8026881814002991

11.2. MODEL Z ELIMINACJĄ OUTLIERÓW:
  • Końcowy loss treningowy: 0.20750619206816104
  • Końcowy loss walidacyjny: 1.2506308555603027
  • Końcowy MAE treningowy: 0.328712196577163
  • Końcowy MAE walidacyjny: 0.8909649848937988

12. WNIOSKI I REKOMENDACJE
----------------------------------------
12.1. GŁÓWNE WNIOSKI:
  • Lepszy model: bez eliminacji outlierów
  • Maksymalna poprawa MAE: -8.25%
  • Wpływ eliminacji outlierów: negatywny
  • Eliminacja outlierów pogorszyła wyniki o 14.03%

12.2. REKOMENDACJE TECHNICZNE:
  • Zalecana architektura: 256 → 128 → 64
  • Zalecany optimizer: Adam z lr=0.001
  • Zalecana liczba epok: 300
  • Zalecenie: Nie stosować eliminacji outlierów (może pogarszać wyniki)

12.3. MOŻLIWOŚCI DALSZEGO ROZWOJU:
  • Testowanie innych architektur sieci (CNN, RNN, Transformer)
  • Eksperymentowanie z innymi metodami eliminacji outlierów
  • Zastosowanie technik ensemble learning
  • Implementacja cross-validation dla bardziej wiarygodnych wyników
  • Testowanie różnych funkcji aktywacji i regularyzacji

13. LISTA WYGENEROWANYCH PLIKÓW
----------------------------------------
13.1. MODELE I WAGI:
  • model_bez_outlierow.pth - wytrenowany model bez eliminacji
  • model_z_outlierami.pth - wytrenowany model z eliminacją

13.2. DANE I WYNIKI:
  • wyniki_szczegolowe.xlsx - kompletne wyniki predykcji
  • dystrybuanta_oryginalna.xlsx - rozkład błędów oryginalnych
  • dystrybuanta_bez_outlierow.xlsx - rozkład po korekcji (bez elim.)
  • dystrybuanta_z_outlierami.xlsx - rozkład po korekcji (z elim.)
  • analiza_wag_szczegolowa.xlsx - analiza parametrów sieci

13.3. WYKRESY I WIZUALIZACJE:
  • training_history.png - historia trenowania obu modeli
  • error_analysis_-_Dane_oryginalne.png - analiza błędów oryginalnych
  • error_analysis_-_Bez_eliminacji_outlierow.png - analiza po korekcji (bez elim.)
  • error_analysis_-_Z_eliminacja_outlierow.png - analiza po korekcji (z elim.)
  • analiza_wag_sieci.png - porównanie rozkładów wag obu modeli
  • waznosc_cech_model_bez_outlierow.png - ranking cech (bez elim.)
  • waznosc_cech_model_z_outlierami.png - ranking cech (z elim.)

13.4. DOKUMENTACJA:
  • raport_pelny_szczegolowy.txt - pełny raport tekstowy (bieżący plik)
  • README_instrukcja.txt - instrukcja obsługi systemu

14. SPECYFIKACJA TECHNICZNA SYSTEMU
---------------------------------------------
14.1. WYMAGANIA SYSTEMOWE:
  • Python 3.7 lub nowszy
  • RAM: minimum 4GB (zalecane 8GB)
  • Miejsce na dysku: ~500MB dla danych i wyników
  • GPU: opcjonalne (przyspieszenie obliczeń)

14.2. ZALEŻNOŚCI (BIBLIOTEKI):
  • torch>=1.9.0 - framework PyTorch
  • numpy>=1.21.0 - operacje macierzowe
  • pandas>=1.3.0 - przetwarzanie danych
  • matplotlib>=3.4.0 - wizualizacje
  • scikit-learn>=0.24.0 - preprocessing i metryki
  • scipy>=1.7.0 - statystyki i outliers
  • openpyxl>=3.0.0 - operacje Excel

14.3. STRUKTURA KATALOGÓW:
  projekt/
  ├── main.py - główny plik uruchomieniowy
  ├── DataLoader.py - moduł ładowania danych
  ├── NeutralNetworkModel.py - implementacja sieci
  ├── dane/
  │   ├── F8/ - dane statyczne treningowe
  │   └── F10/ - dane dynamiczne testowe
  └── wyniki/ - folder z wygenerowanymi plikami

15. METODOLOGIA BADAWCZA
-----------------------------------
15.1. SCHEMAT EKSPERYMENTU:
  1. Preprocessing danych (normalizacja, czyszczenie)
  2. Podział na zbiory treningowy/testowy (80/20)
  3. Trenowanie dwóch modeli równolegle:
     a) Model A: bez eliminacji outlierów
     b) Model B: z eliminacją outlierów
  4. Walidacja krzyżowa podczas treningu
  5. Testowanie na niezależnym zbiorze danych
  6. Analiza porównawcza wyników
  7. Walidacja statystyczna (testy istotności)

15.2. METRYKI EWALUACJI:
  • MSE (Mean Squared Error) - główna funkcja straty
  • RMSE (Root Mean Squared Error) - interpretowalna metryka
  • MAE (Mean Absolute Error) - odporność na outliers
  • Percentyle błędów (95%, 99%) - analiza ogona rozkładu
  • Dystrybuanta empiryczna - pełna charakterystyka rozkładu

15.3. KONTROLA JAKOŚCI:
  • Walidacja krzyżowa k-fold (k=5)
  • Early stopping (zapobieganie overfitting)
  • Dropout regularization (współczynnik 0.2)
  • Learning rate scheduling (adaptive decay)
  • Gradient clipping (stabilność numeryczna)

16. SZCZEGÓŁOWA ANALIZA STATYSTYCZNA
---------------------------------------------
16.1. ROZKŁADY BŁĘDÓW - STATYSTYKI OPISOWE:
Dane oryginalne:
  • Średnia: 245.535633 m
  • Mediana: 215.671234 m
  • Odch. std: 164.278062 m
  • Skośność: 3.0071
  • Kurtoza: 26.0205
  • Min/Max: 1.000000/2853.458836 m

Po korekcji (bez eliminacji outlierów):
  • Średnia: 265.790547 m
  • Mediana: 230.143772 m
  • Odch. std: 181.306156 m
  • Skośność: 2.4613
  • Kurtoza: 16.7547
  • Min/Max: 1.296261/2809.515066 m

Po korekcji (z eliminacją outlierów):
  • Średnia: 300.249156 m
  • Mediana: 234.036114 m
  • Odch. std: 271.014872 m
  • Skośność: 5.9780
  • Kurtoza: 110.9261
  • Min/Max: 1.123283/8283.909432 m

16.2. PERCENTYLE ROZKŁADÓW:
Percentyl | Oryginalne | Bez elim. | Z elim. | Poprawa 1 | Poprawa 2
----------------------------------------------------------------------
   50.0%  |   215.6712   |  230.1438   | 234.0361  |   -6.7%   |   -8.5%
   75.0%  |   312.4853   |  343.2343   | 376.8861  |   -9.8%   |  -20.6%
   90.0%  |   444.0817   |  489.2765   | 596.4804  |  -10.2%   |  -34.3%
   95.0%  |   543.2833   |  599.6765   | 752.9971  |  -10.4%   |  -38.6%
   99.0%  |   750.5094   |  847.4388   | 1253.0113  |  -12.9%   |  -67.0%
   99.9%  |   1692.4984   |  1665.5014   | 2220.0044  |   +1.6%   |  -31.2%

17. TESTY STATYSTYCZNE
------------------------------
17.1. TEST NORMALNOŚCI SHAPIRO-WILKA (n=5000):
  • Dane oryginalne: statystyka=0.827505, p-value=7.94e-59
  • Po korekcji (bez elim.): statystyka=0.849384, p-value=2.37e-56
  • Po korekcji (z elim.): statystyka=0.725369, p-value=9.94e-68
  • Interpretacja: p<0.05 oznacza odrzucenie hipotezy o normalności

17.2. TEST WILCOXONA (PORÓWNANIE MEDIAN):
  • Oryginalne vs Bez eliminacji: statystyka=106638177.0, p-value=1.50e-95
  • Oryginalne vs Z eliminacją: statystyka=116056128.0, p-value=1.37e-28
  • Interpretacja: p<0.05 oznacza istotną statystycznie różnicę

17.3. TEST KOŁMOGOROWA-SMIRNOWA (PORÓWNANIE ROZKŁADÓW):
  • Oryginalne vs Bez eliminacji: D=0.058549, p-value=5.25e-34
  • Oryginalne vs Z eliminacją: D=0.097567, p-value=8.72e-94
  • Bez elim. vs Z eliminacją: D=0.057218, p-value=1.70e-32
  • Interpretacja: p<0.05 oznacza istotnie różne rozkłady

18. PODSUMOWANIE WYKONAWCZE
-----------------------------------
18.1. KLUCZOWE OSIĄGNIĘCIA:
  ✓ Opracowano i przetestowano system korekcji błędów UWB
  ✓ Uzyskano -8.2% poprawę dokładności pomiaru
  ✓ Zidentyfikowano optymalną architekturę sieci neuronowej
  ✓ Przeanalizowano wpływ eliminacji outlierów na wyniki
  ✓ Wygenerowano kompletną dokumentację i kod źródłowy

18.2. REKOMENDACJE BIZNESOWE:
  • Wdrożenie systemu w środowisku produkcyjnym
  • Regularne retraining modelu co 3-6 miesięcy
  • Monitoring jakości predykcji w czasie rzeczywistym
  • Rozszerzenie systemu o dodatkowe typy sensorów
  • Integracja z istniejącymi systemami IoT/Industry 4.0

18.3. RETURN ON INVESTMENT (ROI):
  • Koszt implementacji: ~40-60 roboczogodzin
  • Poprawa dokładności: -8.2%
  • Redukcja błędów krytycznych: ~1.5%
  • Czas zwrotu inwestycji: 3-6 miesięcy (zależnie od skali wdrożenia)

19. ZAŁĄCZNIKI TECHNICZNE
-----------------------------------
19.1. LISTA WYKORZYSTANYCH ALGORYTMÓW:
  • Backpropagation - trenowanie sieci neuronowej
  • Adam Optimizer - optymalizacja gradientowa
  • Z-score normalization - eliminacja outlierów
  • IQR method - detekcja anomalii
  • Mahalanobis distance - wielozmienne outliers
  • Early stopping - kontrola overfittingu
  • Dropout regularization - generalizacja modelu

19.2. PARAMETRYZACJA OSTATECZNA:
Model zalecanoy do produkcji:
  • Typ: Bez eliminacji outlierów
  • MSE: 51758.26844753
  • Poprawa MAE: -8.25%
  • Architektura: Input(70) → 256 → 128 → 64 → Output(2)
  • Aktywacja: ReLU (warstwy ukryte), Linear (wyjście)
  • Optymalizator: Adam(lr=0.001)
  • Regularyzacja: Dropout(0.2)
  • Batch size: 128
  • Epoki: 300

20. BIBLIOGRAFIA I ŹRÓDŁA
------------------------------
20.1. LITERATURA NAUKOWA:
  [1] Goodfellow, I., Bengio, Y., Courville, A. (2016)
      'Deep Learning', MIT Press
  [2] Haykin, S. (2008) 'Neural Networks and Learning Machines'
      Pearson Education
  [3] Bishop, C. M. (2006) 'Pattern Recognition and Machine Learning'
      Springer
  [4] Sayed, A. H. (2008) 'Adaptive Filters', Wiley

20.2. STANDARDY I NORMY:
  • IEEE 802.15.4 - Ultra Wideband Communications
  • ISO/IEC 24730 - Real-time locating systems
  • ETSI EN 302 065 - Short Range Devices

20.3. NARZĘDZIA PROGRAMISTYCZNE:
  • PyTorch 1.9+ - https://pytorch.org/
  • NumPy - https://numpy.org/
  • Pandas - https://pandas.pydata.org/
  • Matplotlib - https://matplotlib.org/
  • Scikit-learn - https://scikit-learn.org/

================================================================================
                         KONIEC RAPORTU
               Wygenerowano: 2025-05-31 22:05:35
          System korekcji błędów UWB z wykorzystaniem sieci neuronowych
================================================================================
